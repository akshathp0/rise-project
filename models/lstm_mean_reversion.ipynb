{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "648c2dbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/xclxh05s0x9509nblm6z434w0000gp/T/ipykernel_2339/2100233776.py:15: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  training_data = yf.download(downloadable_tickers, start = '2015-01-01', end = '2020-01-01')['Close']\n",
      "[*********************100%***********************]  10 of 10 completed\n",
      "/var/folders/qd/xclxh05s0x9509nblm6z434w0000gp/T/ipykernel_2339/2100233776.py:16: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  testing_data = yf.download(downloadable_tickers, start = '2020-01-02', end = '2020-12-31')['Close']\n",
      "[*********************100%***********************]  10 of 10 completed\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "pairs = [['IEMG', 'EEM'], ['ARKK', 'ARKW'], ['TLT', 'SPTL'], ['SHY', 'VGSH'], ['SOXX', 'ITA']]\n",
    "\n",
    "downloadable_tickers = [ticker for pair in pairs for ticker in pair]\n",
    "\n",
    "training_data = yf.download(downloadable_tickers, start = '2015-01-01', end = '2020-01-01')['Close']\n",
    "testing_data = yf.download(downloadable_tickers, start = '2020-01-02', end = '2020-12-31')['Close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "42ab5e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zscore_calc_test(series, mean, std):\n",
    "    return (series - mean) / std\n",
    "\n",
    "def zscore_calc_train(series):\n",
    "    return (series - series.mean()) / series.std(), series.mean(), series.std()\n",
    "\n",
    "training_spreads = {}\n",
    "testing_spreads = {}\n",
    "\n",
    "for etf1, etf2 in pairs:\n",
    "    train_z1, mean_z1, std_z1 = zscore_calc_train(training_data[etf1])\n",
    "    train_z2, mean_z2, std_z2 = zscore_calc_train(training_data[etf2])\n",
    "\n",
    "    test_z1 = zscore_calc_test(testing_data[etf1], mean_z1, std_z1)\n",
    "    test_z2 = zscore_calc_test(testing_data[etf2], mean_z2, std_z2)\n",
    "\n",
    "    training_spread, testing_spread = train_z1 - train_z2, test_z1 - test_z2\n",
    "    training_spreads[f'{etf1}_{etf2}'], testing_spreads[f'{etf1}_{etf2}'] = training_spread, testing_spread\n",
    "\n",
    "training_spreads_df = pd.DataFrame(training_spreads)\n",
    "testing_spreads_df = pd.DataFrame(testing_spreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b9d1adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mean_reversion_label(spread, window = 5, threshold = 0.1):\n",
    "    labels = []\n",
    "    mean = spread.mean()\n",
    "\n",
    "    for i in range(len(spread)):\n",
    "        future_spread = spread[i + 1 : i + 1 + window]\n",
    "        if len(future_spread) < window:\n",
    "            labels.append(np.nan)\n",
    "        elif any(abs(j - mean) < threshold for j in future_spread):\n",
    "            labels.append(1)\n",
    "        else:\n",
    "            labels.append(0)\n",
    "\n",
    "    return pd.Series(labels, index = spread.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "b5619322",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, window_size):\n",
    "    X, y  = [], []\n",
    "\n",
    "    for i in range(len(data) - window_size):\n",
    "        X.append(data[i : i + window_size])\n",
    "        y.append(data[i + window_size])\n",
    "\n",
    "    X_1 = np.array(X)\n",
    "    y_1 = np.array(y)\n",
    "\n",
    "    return torch.tensor(X_1, dtype = torch.float32).unsqueeze(-1), torch.tensor(y_1, dtype = torch.float32).unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "67d89133",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassificationLSTM(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_size=50, num_layers=1):\n",
    "        super(ClassificationLSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_size, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = out[:, -1, :]\n",
    "        out = self.linear(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "00532140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, criterion, optimizer, epochs = 50, device = 'cpu'):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for xb, yb in train_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(xb)\n",
    "            loss = criterion(preds, yb.view(-1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        print(f\"Epoch {epoch+1}/{epochs} - Loss: {total_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "8a6c017b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, test_loader, device = 'cpu'):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_true = []\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            preds = model(xb)\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_true.append(yb.cpu())\n",
    "    y_pred = torch.cat(all_preds).numpy()\n",
    "    y_true = torch.cat(all_true).numpy()\n",
    "    y_pred_label = (y_pred > 0.5).astype(int)\n",
    "    accuracy = accuracy_score(y_true, y_pred_label)\n",
    "    print(\"Test Accuracy:\", accuracy)\n",
    "    return y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "3933e521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pair(pair_name, train_spread, test_spread, window_size=30, threshold=0.2, epochs=20, device='cpu'):\n",
    "    train_labels = predict_mean_reversion_label(train_spread).dropna()\n",
    "    test_labels = predict_mean_reversion_label(test_spread).dropna()\n",
    "    \n",
    "    train_labels = predict_mean_reversion_label(train_spread)\n",
    "    train_spread_aligned = train_spread[train_labels.notna()]\n",
    "    train_spread_aligned = train_labels[train_labels.notna()]\n",
    "    \n",
    "    test_labels = predict_mean_reversion_label(test_spread)\n",
    "    test_spread_aligned = test_spread[test_labels.notna()]\n",
    "    test_spread_aligned = test_labels[test_labels.notna()]\n",
    "    \n",
    "    X_train, y_train = create_sequences(train_spread_aligned.values, window_size)\n",
    "    y_train = y_train[:len(X_train)]\n",
    "    X_test, y_test = create_sequences(test_spread_aligned.values, window_size)\n",
    "    y_test = y_test[:len(X_test)]\n",
    "\n",
    "    y_train = y_train.float()\n",
    "    y_test = y_test.float()\n",
    "    \n",
    "    train_dataset = TensorDataset(X_train, y_train)\n",
    "    test_dataset = TensorDataset(X_test, y_test)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=64, shuffle = False)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=64, shuffle = False)\n",
    "    \n",
    "    model = ClassificationLSTM().to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "    \n",
    "    print(f\"\\nTraining model for pair: {pair_name}\")\n",
    "    train_model(model, train_loader, criterion, optimizer, epochs=epochs, device=device)\n",
    "    \n",
    "    print(f\"\\nEvaluating model for pair: {pair_name}\")\n",
    "    y_true, y_pred = evaluate_model(model, test_loader, device=device)\n",
    "    \n",
    "    return model, y_true, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "4ca3f538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model for pair: IEMG_EEM\n",
      "Epoch 1/50 - Loss: 0.6061\n",
      "Epoch 2/50 - Loss: 0.2152\n",
      "Epoch 3/50 - Loss: 0.0243\n",
      "Epoch 4/50 - Loss: 0.0095\n",
      "Epoch 5/50 - Loss: 0.0056\n",
      "Epoch 6/50 - Loss: 0.0039\n",
      "Epoch 7/50 - Loss: 0.0030\n",
      "Epoch 8/50 - Loss: 0.0025\n",
      "Epoch 9/50 - Loss: 0.0021\n",
      "Epoch 10/50 - Loss: 0.0019\n",
      "Epoch 11/50 - Loss: 0.0016\n",
      "Epoch 12/50 - Loss: 0.0014\n",
      "Epoch 13/50 - Loss: 0.0013\n",
      "Epoch 14/50 - Loss: 0.0011\n",
      "Epoch 15/50 - Loss: 0.0010\n",
      "Epoch 16/50 - Loss: 0.0009\n",
      "Epoch 17/50 - Loss: 0.0009\n",
      "Epoch 18/50 - Loss: 0.0008\n",
      "Epoch 19/50 - Loss: 0.0007\n",
      "Epoch 20/50 - Loss: 0.0007\n",
      "Epoch 21/50 - Loss: 0.0006\n",
      "Epoch 22/50 - Loss: 0.0006\n",
      "Epoch 23/50 - Loss: 0.0006\n",
      "Epoch 24/50 - Loss: 0.0005\n",
      "Epoch 25/50 - Loss: 0.0005\n",
      "Epoch 26/50 - Loss: 0.0005\n",
      "Epoch 27/50 - Loss: 0.0004\n",
      "Epoch 28/50 - Loss: 0.0004\n",
      "Epoch 29/50 - Loss: 0.0004\n",
      "Epoch 30/50 - Loss: 0.0004\n",
      "Epoch 31/50 - Loss: 0.0004\n",
      "Epoch 32/50 - Loss: 0.0003\n",
      "Epoch 33/50 - Loss: 0.0003\n",
      "Epoch 34/50 - Loss: 0.0003\n",
      "Epoch 35/50 - Loss: 0.0003\n",
      "Epoch 36/50 - Loss: 0.0003\n",
      "Epoch 37/50 - Loss: 0.0003\n",
      "Epoch 38/50 - Loss: 0.0003\n",
      "Epoch 39/50 - Loss: 0.0002\n",
      "Epoch 40/50 - Loss: 0.0002\n",
      "Epoch 41/50 - Loss: 0.0002\n",
      "Epoch 42/50 - Loss: 0.0002\n",
      "Epoch 43/50 - Loss: 0.0002\n",
      "Epoch 44/50 - Loss: 0.0002\n",
      "Epoch 45/50 - Loss: 0.0002\n",
      "Epoch 46/50 - Loss: 0.0002\n",
      "Epoch 47/50 - Loss: 0.0002\n",
      "Epoch 48/50 - Loss: 0.0002\n",
      "Epoch 49/50 - Loss: 0.0002\n",
      "Epoch 50/50 - Loss: 0.0002\n",
      "\n",
      "Evaluating model for pair: IEMG_EEM\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Training model for pair: ARKK_ARKW\n",
      "Epoch 1/50 - Loss: 0.6358\n",
      "Epoch 2/50 - Loss: 0.4390\n",
      "Epoch 3/50 - Loss: 0.3296\n",
      "Epoch 4/50 - Loss: 0.3289\n",
      "Epoch 5/50 - Loss: 0.3088\n",
      "Epoch 6/50 - Loss: 0.2612\n",
      "Epoch 7/50 - Loss: 0.2338\n",
      "Epoch 8/50 - Loss: 0.2248\n",
      "Epoch 9/50 - Loss: 0.2165\n",
      "Epoch 10/50 - Loss: 0.2133\n",
      "Epoch 11/50 - Loss: 0.2090\n",
      "Epoch 12/50 - Loss: 0.2042\n",
      "Epoch 13/50 - Loss: 0.2006\n",
      "Epoch 14/50 - Loss: 0.1964\n",
      "Epoch 15/50 - Loss: 0.1920\n",
      "Epoch 16/50 - Loss: 0.1879\n",
      "Epoch 17/50 - Loss: 0.1836\n",
      "Epoch 18/50 - Loss: 0.1792\n",
      "Epoch 19/50 - Loss: 0.1746\n",
      "Epoch 20/50 - Loss: 0.1698\n",
      "Epoch 21/50 - Loss: 0.1646\n",
      "Epoch 22/50 - Loss: 0.1592\n",
      "Epoch 23/50 - Loss: 0.1539\n",
      "Epoch 24/50 - Loss: 0.1492\n",
      "Epoch 25/50 - Loss: 0.1451\n",
      "Epoch 26/50 - Loss: 0.1413\n",
      "Epoch 27/50 - Loss: 0.1376\n",
      "Epoch 28/50 - Loss: 0.1342\n",
      "Epoch 29/50 - Loss: 0.1310\n",
      "Epoch 30/50 - Loss: 0.1279\n",
      "Epoch 31/50 - Loss: 0.1251\n",
      "Epoch 32/50 - Loss: 0.1226\n",
      "Epoch 33/50 - Loss: 0.1204\n",
      "Epoch 34/50 - Loss: 0.1185\n",
      "Epoch 35/50 - Loss: 0.1169\n",
      "Epoch 36/50 - Loss: 0.1142\n",
      "Epoch 37/50 - Loss: 0.1117\n",
      "Epoch 38/50 - Loss: 0.1088\n",
      "Epoch 39/50 - Loss: 0.1067\n",
      "Epoch 40/50 - Loss: 0.1049\n",
      "Epoch 41/50 - Loss: 0.1029\n",
      "Epoch 42/50 - Loss: 0.1035\n",
      "Epoch 43/50 - Loss: 0.1010\n",
      "Epoch 44/50 - Loss: 0.0992\n",
      "Epoch 45/50 - Loss: 0.1001\n",
      "Epoch 46/50 - Loss: 0.0986\n",
      "Epoch 47/50 - Loss: 0.0975\n",
      "Epoch 48/50 - Loss: 0.0947\n",
      "Epoch 49/50 - Loss: 0.0934\n",
      "Epoch 50/50 - Loss: 0.0918\n",
      "\n",
      "Evaluating model for pair: ARKK_ARKW\n",
      "Test Accuracy: 0.8525345622119815\n",
      "\n",
      "Training model for pair: TLT_SPTL\n",
      "Epoch 1/50 - Loss: 0.6233\n",
      "Epoch 2/50 - Loss: 0.2757\n",
      "Epoch 3/50 - Loss: 0.0367\n",
      "Epoch 4/50 - Loss: 0.0124\n",
      "Epoch 5/50 - Loss: 0.0075\n",
      "Epoch 6/50 - Loss: 0.0055\n",
      "Epoch 7/50 - Loss: 0.0044\n",
      "Epoch 8/50 - Loss: 0.0036\n",
      "Epoch 9/50 - Loss: 0.0031\n",
      "Epoch 10/50 - Loss: 0.0026\n",
      "Epoch 11/50 - Loss: 0.0023\n",
      "Epoch 12/50 - Loss: 0.0020\n",
      "Epoch 13/50 - Loss: 0.0018\n",
      "Epoch 14/50 - Loss: 0.0016\n",
      "Epoch 15/50 - Loss: 0.0015\n",
      "Epoch 16/50 - Loss: 0.0013\n",
      "Epoch 17/50 - Loss: 0.0012\n",
      "Epoch 18/50 - Loss: 0.0011\n",
      "Epoch 19/50 - Loss: 0.0010\n",
      "Epoch 20/50 - Loss: 0.0010\n",
      "Epoch 21/50 - Loss: 0.0009\n",
      "Epoch 22/50 - Loss: 0.0008\n",
      "Epoch 23/50 - Loss: 0.0008\n",
      "Epoch 24/50 - Loss: 0.0007\n",
      "Epoch 25/50 - Loss: 0.0007\n",
      "Epoch 26/50 - Loss: 0.0007\n",
      "Epoch 27/50 - Loss: 0.0006\n",
      "Epoch 28/50 - Loss: 0.0006\n",
      "Epoch 29/50 - Loss: 0.0006\n",
      "Epoch 30/50 - Loss: 0.0005\n",
      "Epoch 31/50 - Loss: 0.0005\n",
      "Epoch 32/50 - Loss: 0.0005\n",
      "Epoch 33/50 - Loss: 0.0005\n",
      "Epoch 34/50 - Loss: 0.0004\n",
      "Epoch 35/50 - Loss: 0.0004\n",
      "Epoch 36/50 - Loss: 0.0004\n",
      "Epoch 37/50 - Loss: 0.0004\n",
      "Epoch 38/50 - Loss: 0.0004\n",
      "Epoch 39/50 - Loss: 0.0003\n",
      "Epoch 40/50 - Loss: 0.0003\n",
      "Epoch 41/50 - Loss: 0.0003\n",
      "Epoch 42/50 - Loss: 0.0003\n",
      "Epoch 43/50 - Loss: 0.0003\n",
      "Epoch 44/50 - Loss: 0.0003\n",
      "Epoch 45/50 - Loss: 0.0003\n",
      "Epoch 46/50 - Loss: 0.0003\n",
      "Epoch 47/50 - Loss: 0.0003\n",
      "Epoch 48/50 - Loss: 0.0002\n",
      "Epoch 49/50 - Loss: 0.0002\n",
      "Epoch 50/50 - Loss: 0.0002\n",
      "\n",
      "Evaluating model for pair: TLT_SPTL\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Training model for pair: SHY_VGSH\n",
      "Epoch 1/50 - Loss: 0.5500\n",
      "Epoch 2/50 - Loss: 0.1775\n",
      "Epoch 3/50 - Loss: 0.0177\n",
      "Epoch 4/50 - Loss: 0.0072\n",
      "Epoch 5/50 - Loss: 0.0047\n",
      "Epoch 6/50 - Loss: 0.0036\n",
      "Epoch 7/50 - Loss: 0.0029\n",
      "Epoch 8/50 - Loss: 0.0025\n",
      "Epoch 9/50 - Loss: 0.0021\n",
      "Epoch 10/50 - Loss: 0.0018\n",
      "Epoch 11/50 - Loss: 0.0016\n",
      "Epoch 12/50 - Loss: 0.0014\n",
      "Epoch 13/50 - Loss: 0.0013\n",
      "Epoch 14/50 - Loss: 0.0011\n",
      "Epoch 15/50 - Loss: 0.0010\n",
      "Epoch 16/50 - Loss: 0.0009\n",
      "Epoch 17/50 - Loss: 0.0008\n",
      "Epoch 18/50 - Loss: 0.0008\n",
      "Epoch 19/50 - Loss: 0.0007\n",
      "Epoch 20/50 - Loss: 0.0006\n",
      "Epoch 21/50 - Loss: 0.0006\n",
      "Epoch 22/50 - Loss: 0.0006\n",
      "Epoch 23/50 - Loss: 0.0005\n",
      "Epoch 24/50 - Loss: 0.0005\n",
      "Epoch 25/50 - Loss: 0.0005\n",
      "Epoch 26/50 - Loss: 0.0004\n",
      "Epoch 27/50 - Loss: 0.0004\n",
      "Epoch 28/50 - Loss: 0.0004\n",
      "Epoch 29/50 - Loss: 0.0004\n",
      "Epoch 30/50 - Loss: 0.0004\n",
      "Epoch 31/50 - Loss: 0.0003\n",
      "Epoch 32/50 - Loss: 0.0003\n",
      "Epoch 33/50 - Loss: 0.0003\n",
      "Epoch 34/50 - Loss: 0.0003\n",
      "Epoch 35/50 - Loss: 0.0003\n",
      "Epoch 36/50 - Loss: 0.0003\n",
      "Epoch 37/50 - Loss: 0.0003\n",
      "Epoch 38/50 - Loss: 0.0002\n",
      "Epoch 39/50 - Loss: 0.0002\n",
      "Epoch 40/50 - Loss: 0.0002\n",
      "Epoch 41/50 - Loss: 0.0002\n",
      "Epoch 42/50 - Loss: 0.0002\n",
      "Epoch 43/50 - Loss: 0.0002\n",
      "Epoch 44/50 - Loss: 0.0002\n",
      "Epoch 45/50 - Loss: 0.0002\n",
      "Epoch 46/50 - Loss: 0.0002\n",
      "Epoch 47/50 - Loss: 0.0002\n",
      "Epoch 48/50 - Loss: 0.0002\n",
      "Epoch 49/50 - Loss: 0.0002\n",
      "Epoch 50/50 - Loss: 0.0002\n",
      "\n",
      "Evaluating model for pair: SHY_VGSH\n",
      "Test Accuracy: 1.0\n",
      "\n",
      "Training model for pair: SOXX_ITA\n",
      "Epoch 1/50 - Loss: 0.6888\n",
      "Epoch 2/50 - Loss: 0.6435\n",
      "Epoch 3/50 - Loss: 0.5722\n",
      "Epoch 4/50 - Loss: 0.5490\n",
      "Epoch 5/50 - Loss: 0.4992\n",
      "Epoch 6/50 - Loss: 0.4940\n",
      "Epoch 7/50 - Loss: 0.4452\n",
      "Epoch 8/50 - Loss: 0.4242\n",
      "Epoch 9/50 - Loss: 0.3950\n",
      "Epoch 10/50 - Loss: 0.3709\n",
      "Epoch 11/50 - Loss: 0.3562\n",
      "Epoch 12/50 - Loss: 0.3414\n",
      "Epoch 13/50 - Loss: 0.3289\n",
      "Epoch 14/50 - Loss: 0.3155\n",
      "Epoch 15/50 - Loss: 0.3025\n",
      "Epoch 16/50 - Loss: 0.2915\n",
      "Epoch 17/50 - Loss: 0.2808\n",
      "Epoch 18/50 - Loss: 0.2705\n",
      "Epoch 19/50 - Loss: 0.2634\n",
      "Epoch 20/50 - Loss: 0.2559\n",
      "Epoch 21/50 - Loss: 0.2493\n",
      "Epoch 22/50 - Loss: 0.2443\n",
      "Epoch 23/50 - Loss: 0.2390\n",
      "Epoch 24/50 - Loss: 0.2345\n",
      "Epoch 25/50 - Loss: 0.2305\n",
      "Epoch 26/50 - Loss: 0.2268\n",
      "Epoch 27/50 - Loss: 0.2235\n",
      "Epoch 28/50 - Loss: 0.2203\n",
      "Epoch 29/50 - Loss: 0.2175\n",
      "Epoch 30/50 - Loss: 0.2148\n",
      "Epoch 31/50 - Loss: 0.2123\n",
      "Epoch 32/50 - Loss: 0.2100\n",
      "Epoch 33/50 - Loss: 0.2076\n",
      "Epoch 34/50 - Loss: 0.2056\n",
      "Epoch 35/50 - Loss: 0.2033\n",
      "Epoch 36/50 - Loss: 0.2020\n",
      "Epoch 37/50 - Loss: 0.1996\n",
      "Epoch 38/50 - Loss: 0.2001\n",
      "Epoch 39/50 - Loss: 0.1967\n",
      "Epoch 40/50 - Loss: 0.1956\n",
      "Epoch 41/50 - Loss: 0.1927\n",
      "Epoch 42/50 - Loss: 0.1917\n",
      "Epoch 43/50 - Loss: 0.1900\n",
      "Epoch 44/50 - Loss: 0.1891\n",
      "Epoch 45/50 - Loss: 0.1874\n",
      "Epoch 46/50 - Loss: 0.1888\n",
      "Epoch 47/50 - Loss: 0.1867\n",
      "Epoch 48/50 - Loss: 0.1907\n",
      "Epoch 49/50 - Loss: 0.1832\n",
      "Epoch 50/50 - Loss: 0.1863\n",
      "\n",
      "Evaluating model for pair: SOXX_ITA\n",
      "Test Accuracy: 0.9815668202764977\n",
      "{'IEMG_EEM': {'model': ClassificationLSTM(\n",
      "  (lstm): LSTM(1, 50, batch_first=True)\n",
      "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'y_true': array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'y_pred': array([0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349, 0.9998349,\n",
      "       0.9998349], dtype=float32)}, 'ARKK_ARKW': {'model': ClassificationLSTM(\n",
      "  (lstm): LSTM(1, 50, batch_first=True)\n",
      "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'y_true': array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), 'y_pred': array([0.98937047, 0.98937047, 0.98937047, 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.98937047, 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.98937047, 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.98937047, 0.9212795 , 0.4928875 ,\n",
      "       0.18688658, 0.13641085, 0.16166598, 0.22445758, 0.6915533 ,\n",
      "       0.95801127, 0.98983616, 0.99322754, 0.99296075, 0.99203354,\n",
      "       0.99150556, 0.99163705, 0.9921136 , 0.99259806, 0.9929575 ,\n",
      "       0.9931946 , 0.99336505, 0.99354124, 0.9937828 , 0.9940806 ,\n",
      "       0.99433905, 0.99447906, 0.99448967, 0.9943785 , 0.9941439 ,\n",
      "       0.9937742 , 0.9932422 , 0.9925545 , 0.99182254, 0.991071  ,\n",
      "       0.9903915 , 0.9898693 , 0.989537  , 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.98937047, 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.98937047, 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.98937047, 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.98937047, 0.98937047, 0.98937047,\n",
      "       0.98937047, 0.98937047, 0.9212795 , 0.4928875 , 0.18688658,\n",
      "       0.13641085, 0.16166598, 0.22445758, 0.30088836, 0.7489872 ,\n",
      "       0.9595079 , 0.98569137, 0.9880222 , 0.98579216, 0.9828791 ,\n",
      "       0.98245376, 0.98493654, 0.9881345 , 0.9905714 , 0.9921143 ,\n",
      "       0.9930561 , 0.99364674, 0.99403125, 0.99429363, 0.99449277,\n",
      "       0.9946396 , 0.9946991 , 0.99464613, 0.99447745, 0.99419206,\n",
      "       0.9937709 , 0.99320376, 0.9925545 , 0.99182254, 0.991071  ,\n",
      "       0.9903915 , 0.9898693 , 0.989537  , 0.98937047, 0.9212795 ,\n",
      "       0.4928875 , 0.18688658, 0.13641085, 0.46933687, 0.9030966 ,\n",
      "       0.9876632 , 0.9951409 , 0.995948  , 0.9955947 , 0.96904   ,\n",
      "       0.7419522 , 0.77292824, 0.92858   , 0.9847436 , 0.9936512 ,\n",
      "       0.9950178 , 0.9949726 , 0.99459743, 0.9942584 , 0.9940895 ,\n",
      "       0.9940754 , 0.9941041 , 0.99405044, 0.9939103 , 0.99382   ,\n",
      "       0.9937937 , 0.9935796 , 0.9929766 , 0.9921836 , 0.9914385 ,\n",
      "       0.93685573, 0.55351937, 0.20375738, 0.13585426, 0.15402004,\n",
      "       0.20791365, 0.27447823, 0.32020757, 0.30353618, 0.6325476 ,\n",
      "       0.8991902 , 0.9549649 , 0.9543161 , 0.9294148 , 0.8914212 ,\n",
      "       0.88140047, 0.5525548 , 0.17685789, 0.08981346, 0.07663716,\n",
      "       0.08220592, 0.09357684, 0.10458012, 0.11104392, 0.36133316,\n",
      "       0.79341984, 0.94136953, 0.9546155 , 0.9316324 , 0.8793004 ,\n",
      "       0.8477278 , 0.8809549 , 0.9353503 , 0.7777547 , 0.3161744 ,\n",
      "       0.1421979 , 0.1093391 , 0.365848  , 0.83095837, 0.9664854 ,\n",
      "       0.980548  , 0.97800046, 0.97303164, 0.9754395 , 0.9843113 ,\n",
      "       0.9903763 , 0.9926789 , 0.9934697 , 0.9936128 , 0.99346787,\n",
      "       0.99319047, 0.99285114, 0.9924826 , 0.9921022 , 0.99187076,\n",
      "       0.9918852 , 0.9922184 , 0.992698  , 0.99298877, 0.9929241 ,\n",
      "       0.950996  , 0.61957234, 0.22856866, 0.1388196 , 0.4552561 ,\n",
      "       0.8990534 , 0.9876632 , 0.9951409 , 0.995948  , 0.972647  ,\n",
      "       0.7550534 , 0.34843466], dtype=float32)}, 'TLT_SPTL': {'model': ClassificationLSTM(\n",
      "  (lstm): LSTM(1, 50, batch_first=True)\n",
      "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'y_true': array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'y_pred': array([0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712, 0.9997712,\n",
      "       0.9997712], dtype=float32)}, 'SHY_VGSH': {'model': ClassificationLSTM(\n",
      "  (lstm): LSTM(1, 50, batch_first=True)\n",
      "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'y_true': array([[1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.]], dtype=float32), 'y_pred': array([0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851, 0.999851, 0.999851, 0.999851, 0.999851, 0.999851,\n",
      "       0.999851], dtype=float32)}, 'SOXX_ITA': {'model': ClassificationLSTM(\n",
      "  (lstm): LSTM(1, 50, batch_first=True)\n",
      "  (linear): Linear(in_features=50, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      "), 'y_true': array([[0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [1.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.],\n",
      "       [0.]], dtype=float32), 'y_pred': array([0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.7681504 , 0.9837076 ,\n",
      "       0.98894763, 0.9778512 , 0.90353453, 0.8477935 , 0.95305294,\n",
      "       0.9750167 , 0.94108564, 0.17311272, 0.07486539, 0.15618278,\n",
      "       0.14655168, 0.07409109, 0.05058961, 0.05330988, 0.06904988,\n",
      "       0.09344069, 0.11804622, 0.12968658, 0.12307958, 0.10635725,\n",
      "       0.09007093, 0.07875853, 0.07235265, 0.06941293, 0.8027287 ,\n",
      "       0.9846364 , 0.9884673 , 0.9725441 , 0.8652866 , 0.8638896 ,\n",
      "       0.9630214 , 0.9750244 , 0.9338008 , 0.90346104, 0.96480423,\n",
      "       0.9775763 , 0.94800776, 0.23109162, 0.10111788, 0.20865485,\n",
      "       0.19421451, 0.09038097, 0.05374905, 0.04988608, 0.05906878,\n",
      "       0.07801424, 0.10275302, 0.12170752, 0.123845  , 0.11130746,\n",
      "       0.09481442, 0.08172291, 0.07368987, 0.06976128, 0.06835179,\n",
      "       0.06811434, 0.06769948, 0.06609428, 0.06348353, 0.06067019,\n",
      "       0.05809995, 0.05609066, 0.05500101, 0.05473326, 0.05500261,\n",
      "       0.05537835, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482, 0.05558482, 0.05558482, 0.05558482,\n",
      "       0.05558482, 0.05558482], dtype=float32)}}\n"
     ]
    }
   ],
   "source": [
    "results = {}\n",
    "\n",
    "\n",
    "for pair_name in training_spreads_df.columns:\n",
    "    model, y_true, y_pred = run_pair(\n",
    "        pair_name,\n",
    "        training_spreads_df[pair_name].dropna(),\n",
    "        testing_spreads_df[pair_name].dropna(),\n",
    "        window_size=30,\n",
    "        threshold=0.2,\n",
    "        epochs=50,\n",
    "        device='cpu'\n",
    "    )\n",
    "    results[pair_name] = {'model': model, 'y_true': y_true, 'y_pred': y_pred}\n",
    "\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rise-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
