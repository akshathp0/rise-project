{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5adcbcf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/qd/xclxh05s0x9509nblm6z434w0000gp/T/ipykernel_54856/2726479297.py:44: FutureWarning: YF.download() has changed argument auto_adjust default to True\n",
      "  prices = yf.download(flattened_etfs, start = '2010-01-01', end = '2019-12-31')['Close']\n",
      "[*********************100%***********************]  34 of 34 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Potential Correlated Pairs from sector:\n",
      "    ETF Pair  Correlation\n",
      "26  XLK  XLY     0.847599\n",
      "43  XLB  XLI     0.834225\n",
      "13  XLF  XLI     0.803238\n",
      "Potential Correlated Pairs from sector_twins:\n",
      "      ETF Pair  Correlation\n",
      "221   XLE  VDE     0.995401\n",
      "373   VPU  XLU     0.993256\n",
      "153   VDC  XLP     0.992817\n",
      "21    VFH  XLF     0.992749\n",
      "45    XLK  VGT     0.992254\n",
      "89    XLY  VCR     0.991976\n",
      "285   VIS  XLI     0.991684\n",
      "177   XLV  VHT     0.988901\n",
      "329   VAW  XLB     0.984735\n",
      "397  XLRE  VNQ     0.931970\n",
      "288   VIS  VAW     0.867210\n",
      "108   VCR  VGT     0.853578\n",
      "107   VCR  XLK     0.849241\n",
      "267   XLI  VAW     0.848993\n",
      "67    VGT  XLY     0.848930\n",
      "86    XLY  XLK     0.847599\n",
      "307   XLB  VIS     0.843716\n",
      "266   XLI  XLB     0.834225\n",
      "278   VIS  VCR     0.825231\n",
      "34    VFH  VIS     0.823905\n",
      "273   VIS  XLF     0.818596\n",
      "97    XLY  VIS     0.809018\n",
      "33    VFH  XLI     0.803381\n",
      "252   XLI  XLF     0.803238\n",
      "117   VCR  XLI     0.802500\n",
      "Potential Correlated Pairs from bond:\n",
      "     ETF Pair  Correlation\n",
      "34  SPTL  TLT     0.973310\n",
      "15   IEF  TLH     0.969375\n",
      "27   TLT  TLH     0.967337\n",
      "33  SPTL  TLH     0.956739\n",
      "26   TLT  IEF     0.922544\n",
      "32  SPTL  IEF     0.914772\n",
      "Potential Correlated Pairs from thematic:\n",
      "     ETF  Pair  Correlation\n",
      "23  BOTZ  ROBO     0.929553\n",
      "1   ARKK  ARKW     0.913678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import coint\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import statsmodels.api as sm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.cluster import KMeans\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sector_etfs = ['XLE', 'XLF', 'XLK', 'XLI', 'XLB', 'XLV', 'XLY', 'XLP', 'XLU', 'XLRE'] # Add XLC?\n",
    "sector_twin_etfs = [\n",
    "    'XLF', 'VFH',   # Financials\n",
    "    'XLK', 'VGT',   # Tech\n",
    "    'XLY', 'VCR',   # Consumer Discretionary\n",
    "    'XLP', 'VDC',   # Consumer Staples\n",
    "    'XLV', 'VHT',   # Healthcare\n",
    "    'XLE', 'VDE',   # Energy\n",
    "    'XLI', 'VIS',   # Industrials\n",
    "    'XLB', 'VAW',   # Materials\n",
    "    'XLU', 'VPU',   # Utilities\n",
    "    'XLRE', 'VNQ',  # Real Estate\n",
    "    'VOX',   # Comms without XLC\n",
    "]\n",
    "dividend_etfs = ['VYM', 'HDV', 'SCHD', 'DVY']\n",
    "bond_etfs = ['SHY', 'VGSH', 'IEF', 'TLH', 'TLT', 'SPTL']\n",
    "industry_etfs = ['KBE', 'XOP', 'IHF', 'SOXX', 'ITA', 'IBB']\n",
    "thematic_etfs = ['ARKK', 'ARKW', 'ROBO', 'BOTZ', 'TAN', 'ICLN', 'LIT'] # Add BATT?\n",
    "international_etfs = ['EFA', 'VEA', 'IEMG', 'EEM', 'EWJ', 'EWU', 'EWG', 'FXI', 'EWZ']\n",
    "\n",
    "etf_categories = {\n",
    "    'sector': sector_etfs,\n",
    "    'sector_twins': sector_twin_etfs,\n",
    "    'bond': bond_etfs,\n",
    "    'thematic': thematic_etfs,\n",
    "}\n",
    "\n",
    "\n",
    "flattened_etfs = [etf for etfs in etf_categories.values() for etf in etfs]\n",
    "\n",
    "prices = yf.download(flattened_etfs, start = '2010-01-01', end = '2019-12-31')['Close']\n",
    "\n",
    "for etf in prices.columns:\n",
    "    data = prices[etf]\n",
    "\n",
    "    if data.empty:\n",
    "        print(f\"{etf} does not contain data\")\n",
    "\n",
    "# Pearson correlation\n",
    "\n",
    "for category, etfs in etf_categories.items():\n",
    "    desired_etfs = [etf for etf in etfs]\n",
    "\n",
    "    category_prices = prices[desired_etfs]\n",
    "\n",
    "    returns = category_prices.pct_change().dropna()\n",
    "\n",
    "    correlation_matrix = returns.corr()\n",
    "    correlation_matrix = correlation_matrix.rename_axis(None).rename_axis(None, axis = 1)\n",
    "    correlation_matrix = correlation_matrix.stack().reset_index()\n",
    "    correlation_matrix.columns = ['ETF', 'Pair', 'Correlation']\n",
    "\n",
    "    correlation_matrix =  correlation_matrix[correlation_matrix['ETF'] != correlation_matrix['Pair']]\n",
    "    correlation_matrix = correlation_matrix.sort_values(by = 'Correlation', ascending = False)\n",
    "    correlation_matrix = correlation_matrix.drop_duplicates('Correlation')\n",
    "\n",
    "    potential_pairs = correlation_matrix[correlation_matrix['Correlation'] > 0.8]\n",
    "\n",
    "    print(f\"Potential Correlated Pairs from {category}:\")\n",
    "    print(potential_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33929497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking data point count\n",
    "etf_data_counts = prices.notna().sum().sort_values()\n",
    "\n",
    "etf_data_coverage = etf_data_counts.to_frame(name='Available Days')\n",
    "etf_data_coverage.index.name = 'ETF'\n",
    "\n",
    "print(etf_data_coverage.head(10)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "057a3149",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'etf_categories' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# cointegration\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m category, etfs \u001b[38;5;129;01min\u001b[39;00m etf_categories\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m      5\u001b[0m         candidate_pairs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      7\u001b[0m         desired_etfs \u001b[38;5;241m=\u001b[39m [etf \u001b[38;5;28;01mfor\u001b[39;00m etf \u001b[38;5;129;01min\u001b[39;00m etfs]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'etf_categories' is not defined"
     ]
    }
   ],
   "source": [
    "# cointegration\n",
    "\n",
    "for category, etfs in etf_categories.items():\n",
    "\n",
    "        candidate_pairs = []\n",
    "\n",
    "        desired_etfs = [etf for etf in etfs]\n",
    "\n",
    "        category_prices = prices[desired_etfs]\n",
    "\n",
    "        for i in range(len(desired_etfs)):\n",
    "                for j in range(i + 1, len(desired_etfs)):\n",
    "                        candidate_pairs.append([desired_etfs[i], desired_etfs[j]])\n",
    "\n",
    "        cointegrated_pairs = []\n",
    "\n",
    "        for etf1, etf2 in candidate_pairs:\n",
    "\n",
    "                df = category_prices[[etf1, etf2]].dropna()\n",
    "\n",
    "                s_etf1 = df[etf1]\n",
    "                s_etf2 = df[etf2]\n",
    "\n",
    "                score, pvalue, _ = coint(s_etf1, s_etf2)\n",
    "\n",
    "                if pvalue < 0.05:\n",
    "                        cointegrated_pairs.append((etf1, etf2, pvalue))\n",
    "                        \n",
    "        cointegrated_pairs_df = pd.DataFrame(cointegrated_pairs, columns = ['ETF', 'Pair', 'P-Value'])\n",
    "        cointegrated_pairs_df = cointegrated_pairs_df.sort_values('P-Value').reset_index(drop=True)\n",
    "\n",
    "        print(f\"Cointegration Test Results for {category}:\")\n",
    "        print(cointegrated_pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c40c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rolling cointegration\n",
    "\n",
    "window_size = 504\n",
    "min_passes = 0.4\n",
    "step = 30\n",
    "\n",
    "for category, etfs in etf_categories.items():\n",
    "\n",
    "    candidate_pairs = []\n",
    "    rolling_cointegrated_pairs = []\n",
    "\n",
    "    desired_etfs = [etf for etf in etfs]\n",
    "\n",
    "    category_prices = prices[desired_etfs]\n",
    "\n",
    "    for i in range(len(desired_etfs)):\n",
    "        for j in range(i + 1, len(desired_etfs)):\n",
    "                candidate_pairs.append([desired_etfs[i], desired_etfs[j]])\n",
    "\n",
    "    for etf1, etf2 in candidate_pairs:\n",
    "            \n",
    "        df = category_prices[[etf1, etf2]].dropna()\n",
    "\n",
    "        s_etf1 = df[etf1]\n",
    "        s_etf2 = df[etf2]\n",
    "\n",
    "        df = pd.concat([s_etf1, s_etf2], axis = 1)\n",
    "\n",
    "        if len(df[etf1]) == 0:\n",
    "            print(f\"{etf1} does not have sufficient data\")\n",
    "            continue\n",
    "        elif len(df[etf2]) == 0:\n",
    "            print(f\"{etf2} does not have sufficient data\")\n",
    "            continue\n",
    "            \n",
    "        series1 = df.iloc[:, 0]\n",
    "        series2 = df.iloc[:, 1]\n",
    "\n",
    "        cointegrated_windows = 0\n",
    "        total_windows = 0\n",
    "\n",
    "        for start in range(0, len(df) - window_size + 1, step):\n",
    "            end = start + window_size\n",
    "\n",
    "            window_s1 = series1.iloc[start:end]\n",
    "            window_s2 = series2.iloc[start:end]\n",
    "                \n",
    "            score, pvalue, _ = coint(window_s1, window_s2)\n",
    "            total_windows += 1\n",
    "                \n",
    "            if pvalue < 0.05:\n",
    "                cointegrated_windows += 1\n",
    "\n",
    "        if cointegrated_windows / total_windows >= min_passes:\n",
    "            rolling_cointegrated_pairs.append({'ETF1': etf1, 'ETF2': etf2, 'Pass %': cointegrated_windows / total_windows})\n",
    "\n",
    "\n",
    "    rolling_cointegrated_pairs_df = pd.DataFrame(rolling_cointegrated_pairs)\n",
    "\n",
    "    if rolling_cointegrated_pairs_df.empty:\n",
    "        print(f\"{category} has no rolling cointegrated pairs.\")\n",
    "        continue\n",
    "    else:\n",
    "        rolling_cointegrated_pairs_df = rolling_cointegrated_pairs_df.sort_values('Pass %', ascending = False).reset_index(drop=True)\n",
    "        print(f\"Rolling Cointegration Test Results for {category}:\")\n",
    "        print(rolling_cointegrated_pairs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b958c07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adf test / z-score spread\n",
    "\n",
    "def zscore_calc(series):\n",
    "    return (series - series.mean()) / series.std()\n",
    "\n",
    "def adf_test(series):\n",
    "    test_res = adfuller(series)\n",
    "    return {'stat': test_res[0], 'p-value': test_res[1]}\n",
    "\n",
    "def hedge_ratio_calc(series1, series2):\n",
    "    x = sm.add_constant(series2)\n",
    "    model = sm.OLS(series1, x).fit()\n",
    "\n",
    "    return model.params.iloc[1]\n",
    "\n",
    "\n",
    "for category, etfs in etf_categories.items():\n",
    "\n",
    "    candidate_pairs = []\n",
    "    rolling_cointegrated_pairs = []\n",
    "    results = []\n",
    "\n",
    "    desired_etfs = [etf for etf in etfs]\n",
    "\n",
    "    category_prices = prices[desired_etfs]\n",
    "\n",
    "    for i in range(len(desired_etfs)):\n",
    "        for j in range(i + 1, len(desired_etfs)):\n",
    "                candidate_pairs.append([desired_etfs[i], desired_etfs[j]])\n",
    "\n",
    "    for etf1, etf2 in candidate_pairs:\n",
    "\n",
    "        df = category_prices[[etf1, etf2]].dropna()\n",
    "\n",
    "        s_etf1 = df[etf1]\n",
    "        s_etf2 = df[etf2]\n",
    "\n",
    "        hedge_ratio = hedge_ratio_calc(s_etf1, s_etf2)\n",
    "\n",
    "        spread = s_etf1 - (hedge_ratio * s_etf2)\n",
    "\n",
    "        zscore_spread = zscore_calc(spread)\n",
    "\n",
    "        adf_res = adf_test(spread)\n",
    "\n",
    "        results.append(\n",
    "            {'ETF1': etf1,\n",
    "            'ETF2': etf2,\n",
    "            'adf_value': adf_res['stat'],\n",
    "            'p-value': adf_res['p-value'],\n",
    "            'mean': zscore_spread.mean(),\n",
    "            'std': zscore_spread.std()}\n",
    "        )\n",
    "\n",
    "    results = pd.DataFrame(results)\n",
    "    results = results.sort_values('p-value', ascending = True)\n",
    "    results = results[results['p-value'] < 0.05]\n",
    "\n",
    "    print(f\"ADF Test Results for {category}:\")\n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea7b63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# k-means / PCA\n",
    "\n",
    "for category, etfs in etf_categories.items():\n",
    "    desired_etfs = [etf for etf in etfs]\n",
    "\n",
    "    category_prices = prices[desired_etfs]\n",
    "\n",
    "    returns = category_prices.pct_change().dropna()\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    returns_scaled = scaler.fit_transform(returns.T)\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    pca_components = pca.fit_transform(returns_scaled)\n",
    "\n",
    "    max_clusters = min(len(etfs) - 1, 10)\n",
    "\n",
    "    best_k = 2\n",
    "    best_score = -1\n",
    "\n",
    "    for k in range(2, max_clusters + 1):\n",
    "        kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "        labels = kmeans.fit_predict(pca_components)\n",
    "        score = silhouette_score(pca_components, labels)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "\n",
    "    kmeans = KMeans(n_clusters = best_k, random_state = 42)\n",
    "    labels = kmeans.fit_predict(pca_components)\n",
    "\n",
    "    cluster_df = pd.DataFrame({\n",
    "        'ETF': returns.columns,\n",
    "        'Cluster': labels,\n",
    "        'PC1': pca_components[:, 0],\n",
    "        'PC2': pca_components[:, 1]\n",
    "    })\n",
    "\n",
    "    print(f\"Clusters for {category}:\")\n",
    "    print(cluster_df)\n",
    "\n",
    "    sns.scatterplot(data=cluster_df, x='PC1', y='PC2', hue='Cluster')\n",
    "    plt.title(f\"Clusters for {category}\")\n",
    "    plt.show()\n",
    "\n",
    "    cluster_df = cluster_df.sort_values(by='Cluster')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
